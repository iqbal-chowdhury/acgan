{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exp 4: a simple classifier with the barcode dataset\n",
    "### Shuffle the label, rerun Exp1 to see if there is any underlying linear concept\n",
    "The training data is all 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sugartensor as tf\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64   # batch size\n",
    "image_size = 64\n",
    "pixel_depth = 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "Tensor(\"train_1:1\", shape=(64,), dtype=int64)\n",
      "Tensor(\"train_1:0\", shape=(64, 64, 64, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dir= \"barcode/train/\"\n",
    "fn = os.listdir(dir)\n",
    "total = len(fn)\n",
    "total\n",
    "# put all the images into this blob of size total*size*size*1\n",
    "# REMEMBER to change shape of dataset\n",
    "training_dataset = np.ndarray(shape = (total, image_size, image_size, 1), dtype = np.float32)\n",
    "counter = 0\n",
    "# REMEMBER to change shape of training label\n",
    "training_label = np.ndarray(shape = (total), dtype = np.int64)\n",
    "for file in fn:\n",
    "    image_data = (ndimage.imread(dir+file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "    if True:\n",
    "#         swap label 1 <->7, 3<->2\n",
    "        if int(file[0])==7:\n",
    "            training_label[counter] = 1\n",
    "        if int(file[0])==1:\n",
    "            training_label[counter] = 7\n",
    "        if int(file[0])==3:\n",
    "            training_label[counter] = 2\n",
    "        if int(file[0])==2:\n",
    "            training_label[counter] = 3\n",
    "        if int(file[0]) in [4, 5, 6, 8, 9, 0]:\n",
    "            training_label[counter] = int(file[0])\n",
    "        training_dataset[counter, :, :] = image_data[:,:,0].reshape(image_size, image_size, 1)\n",
    "        counter+=1\n",
    "print(len(training_label))\n",
    "training_image, training_label = tf.sg_data._data_to_tensor([training_dataset, training_label], batch_size, name = \"train\")\n",
    "print(training_label)\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "[8 7 1 7]\n",
      "Tensor(\"train_3:1\", shape=(64,), dtype=int64)\n",
      "Tensor(\"train_3:0\", shape=(64, 64, 64, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB4CAYAAADi1gmcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6426ca1d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir= \"barcode/valid/\"\n",
    "fn = os.listdir(dir)\n",
    "total = len(fn)\n",
    "total\n",
    "valid_label = np.ndarray(shape = (total), dtype = np.int64)\n",
    "valid_dataset = np.ndarray(shape = (total, image_size, image_size, 1), dtype = np.float32)\n",
    "counter = 0\n",
    "for file in fn:\n",
    "    image_data = (ndimage.imread(dir+file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "    if True:\n",
    "        #         swap label 1 <->7, 3<->2\n",
    "        if int(file[0])==7:\n",
    "            valid_label[counter] = 1\n",
    "        if int(file[0])==1:\n",
    "            valid_label[counter] = 7\n",
    "        if int(file[0])==3:\n",
    "            valid_label[counter] = 2\n",
    "        if int(file[0])==2:\n",
    "            valid_label[counter] = 3\n",
    "        if int(file[0]) in [4, 5, 6, 8, 9, 0]:\n",
    "            valid_label[counter] = int(file[0])\n",
    "        valid_dataset[counter, :, :] = image_data[:,:,0].reshape(image_size, image_size, 1)\n",
    "        counter+=1\n",
    "print(len(valid_label))\n",
    "\n",
    "_, axs = plt.subplots(1, 4)\n",
    "\n",
    "label = valid_label[:4]\n",
    "image = valid_dataset[:4]\n",
    "print(label)\n",
    "for i in range(4):\n",
    "    axs[i].imshow(image[i].reshape(image_size, image_size), cmap=plt.cm.Greys);\n",
    "    axs[i].set_title(label[i])\n",
    "\n",
    "valid_image, valid_label = tf.sg_data._data_to_tensor([valid_dataset, valid_label], batch_size, name = \"train\")\n",
    "\n",
    "print(valid_label)\n",
    "print(valid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# input images and label\n",
    "x = training_image\n",
    "y = training_label\n",
    "\n",
    "with tf.sg_context(name='discriminator', size=4, stride=2, act='leaky_relu'):\n",
    "        \n",
    "        # shared part\n",
    "        # have to set batch norm at the layer level because we dont want to use batch norm everywhere\n",
    "        logit = (x\n",
    "                  .sg_conv(dim=64, name = 'conv2', bn = True)\n",
    "                  .sg_conv(dim=128, name='conv3', bn = True)\n",
    "                  .sg_flatten()\n",
    "                  .sg_dense(dim=1024, name='fc1')\n",
    "                  .sg_dense(dim=10, act='linear', name = 'cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"discriminator/cat/out:0\", shape=(64, 10), dtype=float32)\n",
      "Tensor(\"train_1:1\", shape=(64,), dtype=int64)\n",
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "train:   0%|                                   | 0/468 [00:00<?, ?b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  39%|█████████▊               | 183/468 [00:19<00:14, 19.28b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 18.3996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  82%|████████████████████▌    | 386/468 [00:29<00:03, 21.44b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 20.4002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  28%|███████                  | 133/468 [00:05<00:12, 27.86b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.6004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  67%|████████████████▊        | 315/468 [00:15<00:07, 19.68b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 18.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   1%|▏                          | 3/468 [00:00<01:02,  7.45b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 15.4942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  30%|███████▍                 | 140/468 [00:10<00:17, 19.14b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 13.7052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  75%|██████████████████▊      | 352/468 [00:20<00:05, 21.21b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 21.1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  10%|██▋                       | 49/468 [00:04<00:42,  9.93b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 16.6032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  10%|██▌                       | 45/468 [00:02<00:25, 16.88b/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-169c7a5adf77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m        .sg_accuracy(target=valid_label, name='val'))\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# do training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msg_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'asset/train/exp4-classifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sugartensor/sg_train.py\u001b[0m in \u001b[0;36msg_train\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# run train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sugartensor/sg_train.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                         \u001b[0;31m# call train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                         \u001b[0;31m# loss history update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sugartensor/sg_train.py\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m(sess, arg)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msg_train_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# run train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(logit)\n",
    "print(y)\n",
    "loss = logit.sg_ce(target = y, name = 'disc_loss')\n",
    "# limit gpu\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "#\n",
    "# training\n",
    "#\n",
    "# accuracy evaluation\n",
    "acc = (logit.sg_reuse(input = valid_image).sg_softmax()\n",
    "       .sg_accuracy(target=valid_label, name='val'))\n",
    "# do training\n",
    "tf.sg_train(sess = sess, loss = loss, eval_metric=[acc], log_interval=10, max_ep=300, ep_size=30000//batch_size, early_stop=False, save_dir='asset/train/exp4-classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
