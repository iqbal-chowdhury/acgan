{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exp 2: a simple classifier with the barcode dataset\n",
    "### The training data is less than 10 classes\n",
    "The output layer is a classifier layer (one hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sugartensor as tf\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64   # batch size\n",
    "image_size = 32\n",
    "pixel_depth = 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n",
      "Tensor(\"train_1:1\", shape=(64,), dtype=int64)\n",
      "Tensor(\"train_1:0\", shape=(64, 32, 32, 1), dtype=float32)\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "dir= \"barcode/train/\"\n",
    "fn = os.listdir(dir)\n",
    "total = len(fn)\n",
    "total\n",
    "#     change the range to switch between exp2 : [0, 1, 2, 3, 4, 5, 6]\n",
    "#     and exp2.1: [1, 3, 5, 7, 9]\n",
    "visible = [1,3,5,7,9]\n",
    "# put all the images into this blob of size total*size*size*1\n",
    "# REMEMBER to change shape of dataset\n",
    "training_dataset = np.ndarray(shape = (3000*len(visible), image_size, image_size, 1), dtype = np.float32)\n",
    "counter = 0\n",
    "# REMEMBER to change shape of training label\n",
    "training_label = np.ndarray(shape = (3000*len(visible)), dtype = np.int64)\n",
    "for file in fn:\n",
    "    image_data = (ndimage.imread(dir+file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "\n",
    "    if int(file[0]) in visible:\n",
    "        training_label[counter] = int(file[0])\n",
    "        training_dataset[counter, :, :] = image_data[:,:,0].reshape(image_size, image_size, 1)\n",
    "        counter+=1\n",
    "print(len(training_label))\n",
    "training_image, training_label = tf.sg_data._data_to_tensor([training_dataset, training_label], batch_size, name = \"train\")\n",
    "print(training_label)\n",
    "print(training_image)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "[8 1 7 1]\n",
      "Tensor(\"train_3:1\", shape=(64,), dtype=int64)\n",
      "Tensor(\"train_3:0\", shape=(64, 32, 32, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB4CAYAAADi1gmcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3af57d6390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir= \"barcode/valid/\"\n",
    "fn = os.listdir(dir)\n",
    "total = len(fn)\n",
    "total\n",
    "valid_label = np.ndarray(shape = (total), dtype = np.int64)\n",
    "valid_dataset = np.ndarray(shape = (total, image_size, image_size, 1), dtype = np.float32)\n",
    "counter = 0\n",
    "for file in fn:\n",
    "    image_data = (ndimage.imread(dir+file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "    if True:\n",
    "        valid_label[counter] = int(file[0])\n",
    "        valid_dataset[counter, :, :] = image_data[:,:,0].reshape(image_size, image_size, 1)\n",
    "        counter+=1\n",
    "print(len(valid_label))\n",
    "\n",
    "_, axs = plt.subplots(1, 4)\n",
    "\n",
    "label = valid_label[:4]\n",
    "image = valid_dataset[:4]\n",
    "print(label)\n",
    "for i in range(4):\n",
    "    axs[i].imshow(image[i].reshape(image_size, image_size), cmap=plt.cm.Greys);\n",
    "    axs[i].set_title(label[i])\n",
    "\n",
    "valid_image, valid_label = tf.sg_data._data_to_tensor([valid_dataset, valid_label], batch_size, name = \"train\")\n",
    "\n",
    "print(valid_label)\n",
    "print(valid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# input images and label\n",
    "x = training_image\n",
    "y = training_label\n",
    "\n",
    "with tf.sg_context(name='discriminator', size=4, stride=2, act='leaky_relu'):\n",
    "        \n",
    "        # shared part\n",
    "        # have to set batch norm at the layer level because we dont want to use batch norm everywhere\n",
    "        logit = (x\n",
    "                  .sg_conv(dim=64, name = 'conv2', bn = True)\n",
    "                  .sg_conv(dim=128, name='conv3', bn = True)\n",
    "                  .sg_flatten()\n",
    "                  .sg_dense(dim=1024, name='fc1')\n",
    "                  .sg_dense(dim=10, act='linear', name = 'cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"discriminator/cat/out:0\", shape=(64, 10), dtype=float32)\n",
      "Tensor(\"train_1:1\", shape=(64,), dtype=int64)\n",
      "INFO:tensorflow:Restoring parameters from asset/train/exp2.1-classifier/model.ckpt-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "train:   0%|                                   | 0/468 [00:00<?, ?b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  72%|█████████████████▉       | 335/468 [00:09<00:02, 44.71b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 34.4425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  65%|████████████████▏        | 304/468 [00:07<00:03, 41.34b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 43.4001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  55%|█████████████▊           | 259/468 [00:06<00:04, 42.24b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 42.2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  45%|███████████▎             | 212/468 [00:04<00:05, 43.33b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 42.4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  14%|███▌                      | 65/468 [00:03<00:44,  9.16b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 31.6995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  66%|████████████████▌        | 309/468 [00:13<00:03, 44.65b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.3996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  61%|███████████████▏         | 285/468 [00:06<00:04, 43.37b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 44.4001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  53%|█████████████▎           | 250/468 [00:05<00:05, 43.13b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 43.6016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  43%|██████████▊              | 202/468 [00:04<00:06, 42.77b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 42.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  28%|███████                  | 133/468 [00:03<00:07, 44.47b/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e59d705bc4b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msg_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'asset/train/exp2.1-classifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sugartensor/sg_train.py\u001b[0m in \u001b[0;36msg_train\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# run train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sugartensor/sg_train.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                         \u001b[0;31m# call train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                         \u001b[0;31m# loss history update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sugartensor/sg_train.py\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m(sess, arg)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msg_train_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# run train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(logit)\n",
    "print(y)\n",
    "loss = logit.sg_ce(target = y, name = 'disc_loss')\n",
    "# limit gpu\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "#\n",
    "# training\n",
    "#\n",
    "# accuracy evaluation\n",
    "acc = (logit.sg_reuse(input = valid_image).sg_softmax()\n",
    "       .sg_accuracy(target=valid_label, name='val'))\n",
    "# do training\n",
    "dir= \"barcode/train/\"\n",
    "fn = os.listdir(dir)\n",
    "total = len(fn)\n",
    "\n",
    "tf.sg_train(sess = sess, loss = loss, eval_metric=[acc], log_interval=10, max_ep=600, ep_size=total//batch_size, early_stop=False, save_dir='asset/train/exp2.1-classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
