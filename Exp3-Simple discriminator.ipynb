{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exp 3: a simple classifier with the barcode dataset\n",
    "### The training data is less than 10 classes\n",
    "### The output layer is a regression layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sugartensor as tf\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1   # batch size\n",
    "image_size = 64\n",
    "pixel_depth = 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000381204535564\n",
      "1200\n",
      "Tensor(\"train_1:1\", shape=(1,), dtype=float32)\n",
      "Tensor(\"train_1:0\", shape=(1, 64, 64, 1), dtype=float32)\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "dir= \"barcode/train/\"\n",
    "fn = os.listdir(dir)\n",
    "total = len(fn)\n",
    "total\n",
    "#     change the range to switch between exp2 : [0, 1, 2, 3, 4, 5, 6]\n",
    "#     and exp2.1: [1, 3, 5, 7, 9]\n",
    "visible = [1, 2, 4, 7]\n",
    "# put all the images into this blob of size total*size*size*1\n",
    "# REMEMBER to change shape of dataset\n",
    "training_dataset = np.ndarray(shape = (300*len(visible), image_size, image_size, 1), dtype = np.float32)\n",
    "counter = 0\n",
    "# REMEMBER to change shape of training label\n",
    "training_label = np.ndarray(shape = (300*len(visible)), dtype = np.float32)\n",
    "for file in fn:\n",
    "#     image_data = ndimage.imread(dir+file).astype(float)\n",
    "    image_data = (ndimage.imread(dir+file).astype(float) - 250) / pixel_depth\n",
    "    label = int(file.split(\"_\")[0])\n",
    "    if label in visible:\n",
    "        training_label[counter] = int(file[0])\n",
    "        training_dataset[counter, :, :] = image_data[:,:,0].reshape(image_size, image_size, 1)\n",
    "        counter+=1\n",
    "#     else:\n",
    "#         print(file[0])\n",
    "print(np.sum(training_dataset)/(300*len(visible)*image_size*image_size))\n",
    "print(len(training_label))\n",
    "training_image, training_label = tf.sg_data._data_to_tensor([training_dataset, training_label], batch_size, name = \"train\")\n",
    "print(training_label)\n",
    "print(training_image)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  ..., \n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]]\n",
      "\n",
      " [[ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  ..., \n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]]\n",
      "\n",
      " [[ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  ..., \n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]]\n",
      "\n",
      " ..., \n",
      " [[ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  ..., \n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]]\n",
      "\n",
      " [[ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  ..., \n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]]\n",
      "\n",
      " [[ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  ..., \n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]\n",
      "  [ 0.01960784]]]\n"
     ]
    }
   ],
   "source": [
    "print(training_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n",
      "[ 8.  1.  1.  7.  1.  1.  2.]\n",
      "[[[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " ..., \n",
      " [[-0.20784314]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[-0.20784314]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[-0.20784314]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]]\n",
      "[[[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " ..., \n",
      " [[ 0.08627451]\n",
      "  [-0.38431373]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [-0.38431373]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [-0.38431373]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]]\n",
      "[[[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " ..., \n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]]\n",
      "[[[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " ..., \n",
      " [[-0.43921569]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]]\n",
      "[[[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " ..., \n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]]\n",
      "[[[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " ..., \n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]]\n",
      "[[[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " ..., \n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]\n",
      "\n",
      " [[ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  ..., \n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]\n",
      "  [ 0.08627451]]]\n",
      "Tensor(\"train_3:1\", shape=(1,), dtype=float32)\n",
      "Tensor(\"train_3:0\", shape=(1, 64, 64, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABYCAYAAADlegyqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbuhmZon4H6s98EwGWlmLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4eca509cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir= \"barcode/valid/\"\n",
    "fn = os.listdir(dir)\n",
    "total = len(fn)\n",
    "total\n",
    "valid_label = np.ndarray(shape = (total), dtype = np.float32)\n",
    "valid_dataset = np.ndarray(shape = (total, image_size, image_size, 1), dtype = np.float32)\n",
    "counter = 0\n",
    "for file in fn:\n",
    "    image_data = (ndimage.imread(dir+file).astype(float) - \n",
    "                    233) / pixel_depth\n",
    "    if True:\n",
    "        valid_label[counter] = int(file[0])\n",
    "        valid_dataset[counter, :, :] = image_data[:,:,0].reshape(image_size, image_size, 1)\n",
    "        counter+=1\n",
    "print(len(valid_label))\n",
    "\n",
    "_, axs = plt.subplots(1, 7)\n",
    "\n",
    "label = valid_label[:7]\n",
    "image = valid_dataset[:7]\n",
    "print(label)\n",
    "for i in range(7):\n",
    "    print(image[i])\n",
    "    axs[i].imshow(image[i].reshape(image_size, image_size), cmap=plt.cm.Greys);\n",
    "    axs[i].set_title(label[i])\n",
    "\n",
    "valid_image, valid_label = tf.sg_data._data_to_tensor([valid_dataset, valid_label], batch_size, name = \"train\")\n",
    "\n",
    "print(valid_label)\n",
    "print(valid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"discriminator/cat/out:0\", shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# input images and label\n",
    "x = training_image\n",
    "y = training_label\n",
    "\n",
    "with tf.sg_context(name='discriminator', size=4, stride=2, act='leaky_relu'):\n",
    "        \n",
    "        # shared part\n",
    "        # have to set batch norm at the layer level because we dont want to use batch norm everywhere\n",
    "        shared = (x              \n",
    "                  .sg_conv(dim=32, name = 'conv1')\n",
    "                  .sg_conv(dim=64, name = 'conv2')\n",
    "                  .sg_conv(dim=128, name='conv3')\n",
    "                  .sg_flatten()\n",
    "                  .sg_dense(dim = 1024, name = 'fc2')\n",
    "                  .sg_dense(dim=10, act='linear', name = 'cat'))\n",
    "        print(shared)\n",
    "#         add kernel trick\n",
    "        kernel = tf.concat([tf.pow(shared, 2), shared], 1)\n",
    "        logit = (kernel.sg_dense(dim=1, act = 'linear', name = 'output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"discriminator/concat:0\", shape=(1, 20), dtype=float32)\n",
      "Tensor(\"discriminator/output/out:0\", shape=(1, 1), dtype=float32)\n",
      "Tensor(\"train_1:1\", shape=(1,), dtype=float32)\n",
      "Tensor(\"mse:0\", shape=(1, 1), dtype=float32)\n",
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  25%|█████▉                  | 177/720 [00:00<00:01, 347.29b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 186.146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  46%|███████████▏            | 334/720 [00:01<00:01, 298.72b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 320.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  80%|███████████████████▎    | 578/720 [00:01<00:00, 376.97b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 334.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  17%|████                    | 120/720 [00:00<00:01, 394.42b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 337.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  55%|█████████████▎          | 399/720 [00:02<00:02, 125.08b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 198.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  57%|█████████████▊          | 414/720 [00:02<00:02, 107.20b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 146.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  60%|██████████████▍         | 432/720 [00:01<00:01, 160.63b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 292.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  72%|█████████████████▍      | 522/720 [00:01<00:00, 388.97b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 305.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   5%|█▎                       | 36/720 [00:00<00:01, 357.98b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 335.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "print(kernel)\n",
    "print(logit)\n",
    "print(y)\n",
    "loss = logit.sg_mse(target = y, name = 'disc_loss')\n",
    "# loss = tf.reduce_sum(tf.pow(y-logit, 2), name = \"disc_loss\")/(2*batch_size)\n",
    "print(loss)\n",
    "# limit gpu\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "tf.sg_init(sess)\n",
    "\n",
    "# sess.run(logit)\n",
    "# print(logit)\n",
    "# sess.run(loss)\n",
    "# print(loss)\n",
    "#\n",
    "# training\n",
    "#\n",
    "# accuracy evaluation\n",
    "# acc = (logit.sg_reuse(input = valid_image).sg_int().sg_one_hot(depth = 10)\n",
    "#        .sg_accuracy(target=valid_label, name='val'))\n",
    "# do training\n",
    "\n",
    "# tf.sg_train(optim = 'Adam', sess = sess,  lr = 0.001, loss = loss, log_interval=5, max_ep=900, ep_size=300*len(visible)//batch_size, early_stop=False, save_dir='asset/train/exp3-classifier')\n",
    "# print(\"change learning rate\")\n",
    "# tf.sg_train(optim = 'Adam', sess = sess,  lr = 0.01, loss = loss, log_interval=5, max_ep=120, ep_size=3000*len(visible)//batch_size, early_stop=False, save_dir='asset/train/exp3-classifier')\n",
    "# print(\"change learning rate\")\n",
    "tf.sg_train(optim = 'Adam', sess = sess,  lr = 0.0001, loss = loss, log_interval=5, max_ep=180, ep_size=180*len(visible)//batch_size, early_stop=False, save_dir='asset/train/exp3.2-classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
