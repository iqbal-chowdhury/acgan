{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sugartensor as tf\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 40   # batch size\n",
    "cat_dim = 5   # total categorical factor\n",
    "con_dim = 2    # total continuous factor\n",
    "rand_dim = 38  # total random latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir= \"DCGAN-tensorflow/data/barcode36/\"\n",
    "fn = os.listdir(dir)\n",
    "total = len(fn)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_size = 36\n",
    "pixel_depth = 255.0\n",
    "# put all the images into this blob of size 10kx108x108x3\n",
    "dataset = np.ndarray(shape = (total, 36, 36, 1), dtype = np.float32)\n",
    "counter = 0\n",
    "training_label = np.ndarray(shape = (total), dtype = np.int64)\n",
    "for file in fn:\n",
    "    image_data = (ndimage.imread(dir+file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "    if image_data.shape != (36, 36, 3):\n",
    "        print(\"wrong size\")\n",
    "#     print(file[4])\n",
    "    training_label[counter] = int(file[4])-1\n",
    "    dataset[counter, :, :] = image_data[:,:,0:1]\n",
    "    counter+=1\n",
    "training_image, training_label = tf.sg_data._data_to_tensor([dataset, training_label], batch_size, name = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'train_1:0' shape=(40, 36, 36, 1) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'train_1:1' shape=(40,) dtype=int64>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# generator network\n",
    "def generator(tensor):\n",
    "\n",
    "    # reuse flag\n",
    "    reuse = len([t for t in tf.global_variables() if t.name.startswith('generator')]) > 0\n",
    "\n",
    "    with tf.sg_context(name='generator', size=4, stride=2, act='relu', bn=True, reuse=reuse):\n",
    "        res = (tensor\n",
    "               .sg_dense(dim=1024, name='fc1')\n",
    "               .sg_dense(dim=9*9*128, name='fc2')\n",
    "               .sg_reshape(shape=(-1, 9, 9, 128))\n",
    "               .sg_upconv(dim=64, name='conv1')\n",
    "               .sg_upconv(dim=1, act='sigmoid', bn=False, name='conv2'))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def discriminator(tensor):\n",
    "\n",
    "    # reuse flag\n",
    "    reuse = len([t for t in tf.global_variables() if t.name.startswith('discriminator')]) > 0\n",
    "\n",
    "    with tf.sg_context(name='discriminator', size=4, stride=2, act='leaky_relu', reuse=reuse):\n",
    "        # shared part\n",
    "        shared = (tensor\n",
    "                  .sg_conv(dim=32, name='conv1')\n",
    "                  .sg_conv(dim=128, name='conv3')\n",
    "                  .sg_flatten()\n",
    "                  .sg_dense(dim=1024, name='fc1'))\n",
    "\n",
    "        # discriminator end\n",
    "        disc = shared.sg_dense(dim=1, act='linear', name='disc').sg_squeeze()\n",
    "\n",
    "        # shared recognizer part\n",
    "        recog_shared = shared.sg_dense(dim=128, name='recog')\n",
    "\n",
    "        # categorical auxiliary classifier end\n",
    "        cat = recog_shared.sg_dense(dim=cat_dim, act='linear', name='cat')\n",
    "\n",
    "        # continuous auxiliary classifier end\n",
    "        con = recog_shared.sg_dense(dim=con_dim, act='sigmoid', name='con')\n",
    "\n",
    "        return disc, cat, con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# inputs\n",
    "#\n",
    "\n",
    "# input images and label\n",
    "x = training_image\n",
    "y = training_label\n",
    "\n",
    "# labels for discriminator\n",
    "y_real = tf.ones(batch_size)\n",
    "y_fake = tf.zeros(batch_size)\n",
    "\n",
    "# discriminator labels ( half 1s, half 0s )\n",
    "y_disc = tf.concat([y, y * 0], 0)\n",
    "\n",
    "# categorical latent variable\n",
    "z_cat = tf.multinomial(tf.ones((batch_size, cat_dim), dtype=tf.sg_floatx) / cat_dim, 1).sg_squeeze().sg_int()\n",
    "# continuous latent variable\n",
    "z_con = tf.random_normal((batch_size, con_dim))\n",
    "# random latent variable dimension\n",
    "z_rand = tf.random_normal((batch_size, rand_dim))\n",
    "# latent variable\n",
    "z = tf.concat([z_cat.sg_one_hot(depth=cat_dim), z_con, z_rand], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'generator/conv2/out:0' shape=(?, 36, 36, 1) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Computational graph\n",
    "#\n",
    "\n",
    "# generator\n",
    "gen = generator(z)\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# add image summary\n",
    "tf.sg_summary_image(x, name='real')\n",
    "tf.sg_summary_image(gen, name='fake')\n",
    "\n",
    "# discriminator\n",
    "disc_real, cat_real, _ = discriminator(x)\n",
    "disc_fake, cat_fake, con_fake = discriminator(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'generator/conv2/out:0' shape=(?, 36, 36, 1) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global_step/sec: 56.1438\n",
      "INFO:tensorflow:global_step/sec: 59.8\n",
      "INFO:tensorflow:global_step/sec: 62.0001\n",
      "INFO:tensorflow:global_step/sec: 62.9261\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# loss\n",
    "#\n",
    "\n",
    "# discriminator loss\n",
    "loss_d_r = disc_real.sg_bce(target=y_real, name='disc_real')\n",
    "loss_d_f = disc_fake.sg_bce(target=y_fake, name='disc_fake')\n",
    "loss_d = (loss_d_r + loss_d_f) / 2\n",
    "\n",
    "loss_d\n",
    "\n",
    "# generator loss\n",
    "loss_g = disc_fake.sg_bce(target=y_real, name='gen')\n",
    "\n",
    "# categorical factor loss\n",
    "loss_c_r = cat_real.sg_ce(target=y, name='cat_real')\n",
    "loss_c_d = cat_fake.sg_ce(target=z_cat, name='cat_fake')\n",
    "loss_c = (loss_c_r + loss_c_d) / 2\n",
    "\n",
    "# continuous factor loss\n",
    "loss_con = con_fake.sg_mse(target=z_con, name='con').sg_mean(dims=1)\n",
    "\n",
    "\n",
    "#\n",
    "# train ops\n",
    "#\n",
    "\n",
    "# discriminator train ops\n",
    "train_disc = tf.sg_optim(loss_d + loss_c + loss_con, lr=0.0001, category='discriminator')\n",
    "# generator train ops\n",
    "train_gen = tf.sg_optim(loss_g + loss_c + loss_con, lr=0.001, category='generator')\n",
    "\n",
    "# limit gpu mem to 4GB\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "#\n",
    "# training\n",
    "#\n",
    "\n",
    "# def alternate training func\n",
    "\n",
    "@tf.sg_train_func\n",
    "\n",
    "def alt_train(sess, opt):\n",
    "    l_disc = sess.run([loss_d, train_disc])[0]  # training discriminator\n",
    "    l_gen = sess.run([loss_g, train_gen])[0]  # training generator\n",
    "    return np.mean(l_disc) + np.mean(l_gen)\n",
    "\n",
    "# do training\n",
    "alt_train(sess = sess, log_interval=60, max_ep=30, ep_size=total//batch_size, early_stop=False, save_dir='asset/train/acgan-barcode36', tqdm = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
