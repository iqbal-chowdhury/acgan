{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./asset/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./asset/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./asset/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./asset/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I 0421:04:53:36.727:sg_train.py:327] Training started from epoch[000]-step[0].\n",
      "train:  23%|█████▌                  | 402/1718 [00:09<00:29, 45.06b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 81.3651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  51%|████████████▏           | 876/1718 [00:19<00:19, 44.22b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 94.6017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  79%|██████████████████▏    | 1358/1718 [00:29<00:07, 45.29b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 96.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I 0421:04:54:14.360:sg_train.py:301] \tEpoch[000:gs=3436] - loss = 1.428414\n",
      "train:   6%|█▍                      | 101/1718 [00:02<00:33, 48.73b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 92.6001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  34%|████████                | 581/1718 [00:12<00:26, 42.52b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 95.6006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  61%|██████████████         | 1050/1718 [00:22<00:14, 45.09b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 94.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  89%|████████████████████▍  | 1523/1718 [00:32<00:03, 50.15b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 95.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I 0421:04:54:50.431:sg_train.py:301] \tEpoch[001:gs=6872] - loss = 1.433505\n",
      "train:  17%|████                    | 288/1718 [00:06<00:28, 49.59b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 96.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  44%|██████████▋             | 763/1718 [00:16<00:20, 46.06b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 94.4001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I 0421:04:55:26.797:sg_train.py:301] \tEpoch[002:gs=10308] - loss = 1.438771\n",
      "I 0421:04:56:03.790:sg_train.py:301] \tEpoch[003:gs=13744] - loss = 1.430687\n",
      "I 0421:04:56:40.675:sg_train.py:301] \tEpoch[004:gs=17180] - loss = 1.459116\n",
      "I 0421:04:57:17.722:sg_train.py:301] \tEpoch[005:gs=20616] - loss = 1.454191\n",
      "I 0421:04:57:54.223:sg_train.py:301] \tEpoch[006:gs=24052] - loss = 1.462838\n",
      "I 0421:04:58:29.565:sg_train.py:301] \tEpoch[007:gs=27488] - loss = 1.487397\n",
      "I 0421:04:59:03.272:sg_train.py:301] \tEpoch[008:gs=30924] - loss = 1.499143\n",
      "I 0421:04:59:36.898:sg_train.py:301] \tEpoch[009:gs=34360] - loss = 1.494002\n",
      "I 0421:05:00:10.604:sg_train.py:301] \tEpoch[010:gs=37796] - loss = 1.499426\n",
      "I 0421:05:00:44.384:sg_train.py:301] \tEpoch[011:gs=41232] - loss = 1.494208\n",
      "I 0421:05:01:17.978:sg_train.py:301] \tEpoch[012:gs=44668] - loss = 1.526422\n",
      "I 0421:05:01:51.472:sg_train.py:301] \tEpoch[013:gs=48104] - loss = 1.577077\n",
      "I 0421:05:02:24.942:sg_train.py:301] \tEpoch[014:gs=51540] - loss = 1.526411\n",
      "I 0421:05:02:58.640:sg_train.py:301] \tEpoch[015:gs=54976] - loss = 1.562930\n",
      "I 0421:05:03:32.683:sg_train.py:301] \tEpoch[016:gs=58412] - loss = 1.597601\n",
      "I 0421:05:04:06.825:sg_train.py:301] \tEpoch[017:gs=61848] - loss = 1.611832\n",
      "I 0421:05:04:40.662:sg_train.py:301] \tEpoch[018:gs=65284] - loss = 1.624217\n",
      "I 0421:05:05:14.493:sg_train.py:301] \tEpoch[019:gs=68720] - loss = 1.597206\n",
      "I 0421:05:05:48.482:sg_train.py:301] \tEpoch[020:gs=72156] - loss = 1.641962\n",
      "I 0421:05:06:22.530:sg_train.py:301] \tEpoch[021:gs=75592] - loss = 1.634362\n",
      "I 0421:05:06:56.628:sg_train.py:301] \tEpoch[022:gs=79028] - loss = 1.706715\n",
      "I 0421:05:07:30.492:sg_train.py:301] \tEpoch[023:gs=82464] - loss = 1.746228\n",
      "I 0421:05:08:04.501:sg_train.py:301] \tEpoch[024:gs=85900] - loss = 1.728986\n",
      "I 0421:05:08:38.329:sg_train.py:301] \tEpoch[025:gs=89336] - loss = 1.722055\n",
      "I 0421:05:09:12.441:sg_train.py:301] \tEpoch[026:gs=92772] - loss = 1.763385\n",
      "I 0421:05:09:46.207:sg_train.py:301] \tEpoch[027:gs=96208] - loss = 1.755239\n",
      "I 0421:05:10:19.974:sg_train.py:301] \tEpoch[028:gs=99644] - loss = 1.710674\n",
      "I 0421:05:10:53.984:sg_train.py:301] \tEpoch[029:gs=103080] - loss = 1.795158\n",
      "I 0421:05:11:27.895:sg_train.py:301] \tEpoch[030:gs=106516] - loss = 1.833635\n",
      "I 0421:05:11:28.489:sg_train.py:368] Training finished at epoch[30]-step[106516].\n"
     ]
    }
   ],
   "source": [
    "import sugartensor as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "__author__ = 'namju.kim@kakaobrain.com'\n",
    "\n",
    "# only use gpu 0\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# set log level to debug\n",
    "tf.sg_verbosity(10)\n",
    "\n",
    "#\n",
    "# hyper parameters\n",
    "#\n",
    "\n",
    "batch_size = 32   # batch size\n",
    "cat_dim = 10   # total categorical factor\n",
    "con_dim = 2    # total continuous factor\n",
    "rand_dim = 38  # total random latent dimension\n",
    "\n",
    "\n",
    "#\n",
    "# create generator & discriminator function\n",
    "#\n",
    "\n",
    "def generator(tensor):\n",
    "\n",
    "    # reuse flag\n",
    "    reuse = len([t for t in tf.global_variables() if t.name.startswith('generator')]) > 0\n",
    "\n",
    "    with tf.sg_context(name='generator', size=4, stride=2, act='leaky_relu', bn=True, reuse=reuse):\n",
    "        res = (tensor\n",
    "               .sg_dense(dim=1024, name='fc1')\n",
    "               .sg_dense(dim=7*7*128, name='fc2')\n",
    "               .sg_reshape(shape=(-1, 7, 7, 128))\n",
    "               .sg_upconv(dim=64, name='conv1')\n",
    "               .sg_upconv(dim=1, act='sigmoid', bn=False, name='conv2'))\n",
    "    return res\n",
    "\n",
    "\n",
    "def discriminator(tensor):\n",
    "\n",
    "    # reuse flag\n",
    "    reuse = len([t for t in tf.global_variables() if t.name.startswith('discriminator')]) > 0\n",
    "\n",
    "    with tf.sg_context(name='discriminator', size=4, stride=2, act='leaky_relu', bn=True, reuse=reuse):\n",
    "        # shared part\n",
    "        shared = (tensor\n",
    "                  .sg_conv(dim=64, name='conv1')\n",
    "                  .sg_conv(dim=128, name='conv2')\n",
    "                  .sg_flatten()\n",
    "                  .sg_dense(dim=1024, name='fc1'))\n",
    "\n",
    "        # discriminator end\n",
    "        disc = shared.sg_dense(dim=1, act='linear', bn=False, name='disc').sg_squeeze()\n",
    "\n",
    "        # shared recognizer part\n",
    "        recog_shared = shared.sg_dense(dim=128, name='recog')\n",
    "\n",
    "        # categorical auxiliary classifier end\n",
    "        cat = recog_shared.sg_dense(dim=cat_dim, act='linear', bn=False, name='cat')\n",
    "\n",
    "        # continuous auxiliary classifier end\n",
    "        con = recog_shared.sg_dense(dim=con_dim, act='sigmoid', bn=False, name='con')\n",
    "\n",
    "        return disc, cat, con\n",
    "\n",
    "\n",
    "#\n",
    "# inputs\n",
    "#\n",
    "\n",
    "# MNIST input tensor ( with QueueRunner )\n",
    "data = tf.sg_data.Mnist(batch_size=batch_size)\n",
    "\n",
    "# input images and label\n",
    "x = data.train.image\n",
    "\n",
    "# labels for discriminator\n",
    "y_real = tf.ones(batch_size)\n",
    "y_fake = tf.zeros(batch_size)\n",
    "\n",
    "# categorical latent variable\n",
    "z_cat = tf.multinomial(tf.ones((batch_size, cat_dim), dtype=tf.sg_floatx) / cat_dim, 1).sg_squeeze().sg_int()\n",
    "# continuous latent variable\n",
    "z_con = tf.random_uniform((batch_size, con_dim))\n",
    "# random latent variable dimension\n",
    "z_rand = tf.random_uniform((batch_size, rand_dim))\n",
    "# latent variable\n",
    "z = tf.concat([z_cat.sg_one_hot(depth=cat_dim), z_con, z_rand], 1)\n",
    "\n",
    "\n",
    "#\n",
    "# Computational graph\n",
    "#\n",
    "\n",
    "# generator\n",
    "gen = generator(z)\n",
    "\n",
    "# add image summary\n",
    "tf.sg_summary_image(x, name='real')\n",
    "tf.sg_summary_image(gen, name='fake')\n",
    "\n",
    "# discriminator\n",
    "disc_real, _, _ = discriminator(x)\n",
    "disc_fake, cat_fake, con_fake = discriminator(gen)\n",
    "\n",
    "\n",
    "#\n",
    "# loss\n",
    "#\n",
    "\n",
    "# discriminator loss\n",
    "loss_d_r = disc_real.sg_bce(target=y_real, name='disc_real')\n",
    "loss_d_f = disc_fake.sg_bce(target=y_fake, name='disc_fake')\n",
    "loss_d = (loss_d_r + loss_d_f) / 2\n",
    "\n",
    "\n",
    "# generator loss\n",
    "loss_g = disc_fake.sg_bce(target=y_real, name='gen')\n",
    "\n",
    "# categorical factor loss\n",
    "loss_c = cat_fake.sg_ce(target=z_cat, name='cat')\n",
    "\n",
    "# continuous factor loss\n",
    "loss_con = con_fake.sg_mse(target=z_con, name='con').sg_mean(axis=1)\n",
    "\n",
    "\n",
    "#\n",
    "# train ops\n",
    "#\n",
    "\n",
    "# discriminator train ops\n",
    "train_disc = tf.sg_optim(loss_d + loss_c + loss_con, lr=0.0001, category='discriminator')\n",
    "# generator train ops\n",
    "# maybe no need for loss_c and loss_con? why would you want that\n",
    "train_gen = tf.sg_optim(loss_g + loss_c + loss_con, lr=0.001, category='generator')\n",
    "\n",
    "\n",
    "#\n",
    "# training\n",
    "#\n",
    "\n",
    "# def alternate training func\n",
    "@tf.sg_train_func\n",
    "def alt_train(sess, opt):\n",
    "    l_disc = sess.run([loss_d, train_disc])[0]  # training discriminator\n",
    "    l_gen = sess.run([loss_g, train_gen])[0]  # training generator\n",
    "    return np.mean(l_disc) + np.mean(l_gen)\n",
    "\n",
    "# do training\n",
    "alt_train(log_interval=10, max_ep=30, ep_size=data.train.num_batch, early_stop=False,\n",
    "          save_dir='asset/train/infogan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
