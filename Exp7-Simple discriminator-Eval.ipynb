{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exp 7: a validation script for Exp 7\n",
    "### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sugartensor as tf\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1  # batch size\n",
    "image_size = 64\n",
    "pixel_depth = 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir= \"barcode/valid/\"\n",
    "fn = os.listdir(dir)\n",
    "total = len(fn)\n",
    "total\n",
    "#     change the range to switch between exp2 : [0, 1, 2, 3, 4, 5, 6]\n",
    "#     and exp2.1: [1, 3, 5, 7, 9]\n",
    "visible = range(15)\n",
    "# put all the images into this blob of size total*size*size*1\n",
    "# REMEMBER to change shape of dataset\n",
    "valid_dataset = np.ndarray(shape = (3000*len(visible), image_size, image_size, 1), dtype = np.float32)\n",
    "counter = 0\n",
    "# REMEMBER to change shape of valid label\n",
    "valid_label = np.ndarray(shape = (3000*len(visible)), dtype = np.float32)\n",
    "for file in fn:\n",
    "#     image_data = ndimage.imread(dir+file).astype(float)\n",
    "    image_data = (ndimage.imread(dir+file).astype(float) - 255/2) / pixel_depth\n",
    "    label = int(file.split(\"_\")[0])\n",
    "    if label in visible:\n",
    "        valid_label[counter] = label\n",
    "        valid_dataset[counter, :, :] = image_data[:,:,0].reshape(image_size, image_size, 1)\n",
    "        counter+=1\n",
    "#     else:\n",
    "#         print(file[0])\n",
    "# shuffle dataset\n",
    "permutation = np.random.permutation(counter)\n",
    "valid_dataset = valid_dataset[permutation,:,:,:]\n",
    "valid_label = valid_label[permutation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1024]\n",
      "Tensor(\"lstm/rnn/transpose:0\", shape=(1, 1024, 30), dtype=float32)\n",
      "Tensor(\"lstm/Gather:0\", shape=(1, 30), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_data_node = tf.placeholder(tf.float32, shape=(batch_size, image_size, image_size, 1))\n",
    "\n",
    "train_labels_node = tf.placeholder(tf.float32, shape =(batch_size, 1))\n",
    "\n",
    "def print_variable():\n",
    "    for v in tf.global_variables():\n",
    "        print(v)\n",
    "# capping stddev at 0.1 is important to avoid exploding value\n",
    "def conv_relu(input, kernel_shape, bias_shape, stride = 2):\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape, initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    biases = tf.get_variable(\"biases\", bias_shape, initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights, strides = [1, stride, stride, 1], padding = 'SAME')\n",
    "    return tf.nn.relu(conv+biases)\n",
    "def fully_connected(input, out_shape):\n",
    "    input_shape = input.get_shape().as_list()\n",
    "    batch = input_shape[0]\n",
    "    flattened_size = input_shape[1]\n",
    "    weights = tf.get_variable(\"weights\", [flattened_size, out_shape], \n",
    "                              initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "    biases = tf.get_variable(\"biases\", [out_shape],\n",
    "                            initializer = tf.constant_initializer(0.1))\n",
    "    return tf.matmul(input, weights) + biases\n",
    "def network(input_images):\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        # kernel is in shape height*width*in*out\n",
    "        conv_relu1 = conv_relu(input_images, [4, 4, 1, 32], [32])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        conv_relu2 = conv_relu(conv_relu1, [4, 4, 32, 64], [64])\n",
    "    with tf.variable_scope(\"conv3\"):\n",
    "        conv_relu3 = conv_relu(conv_relu2, [4, 4, 64, 128], [128])\n",
    "    with tf.variable_scope(\"fc1\"):\n",
    "        conv_relu3_shape = conv_relu3.get_shape().as_list()\n",
    "        reshape_conv3 = tf.reshape(conv_relu3,\n",
    "                                [conv_relu3_shape[0], conv_relu3_shape[1]*conv_relu3_shape[2]*conv_relu3_shape[3]])\n",
    "        fc1 = tf.nn.relu(fully_connected(reshape_conv3, 1024))\n",
    "    with tf.variable_scope(\"lstm\"):\n",
    "        num_hidden = 30\n",
    "        fc1_shape = fc1.get_shape().as_list()\n",
    "        print(fc1_shape)\n",
    "        fc1_reshape = tf.reshape(fc1, [fc1_shape[0], fc1_shape[1], 1])\n",
    "        cell = tf.contrib.rnn.LSTMCell(num_hidden, state_is_tuple=True)\n",
    "        val, _ = tf.nn.dynamic_rnn(cell, fc1_reshape, dtype = tf.float32)\n",
    "        print(val)\n",
    "        val = tf.transpose(val, [1, 0, 2]) #transpose to easily get the last state\n",
    "        last = tf.gather(val, int(val.get_shape()[0]) - 1)\n",
    "        print(last)\n",
    "        weight = tf.Variable(tf.truncated_normal([num_hidden, 1]))\n",
    "        bias = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "        output = tf.matmul(last, weight)+bias\n",
    "    return output\n",
    "    \n",
    "output = network(train_data_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./pureTensorflowExp/Exp7/19500.ckpt\n",
      "[ 12.   1.  11.   9.   7.   0.   1.  13.   0.   7.   2.  12.  13.   7.   9.\n",
      "   3.  10.   7.   6.   8.]\n",
      "[9.0, 1.0, 9.0, 9.0, 7.0, 0.0, 1.0, 9.0, 0.0, 7.0, 2.0, 9.0, 9.0, 7.0, 9.0, 3.0, 9.0, 7.0, 6.0, 8.0]\n",
      "accuracy: 0.5217777777777778\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess.as_default()\n",
    "saver.restore(sess, \"./pureTensorflowExp/Exp7/19500.ckpt\")\n",
    "\n",
    "\n",
    "offset = 0\n",
    "batch_data_all = valid_label\n",
    "results = []\n",
    "correct = 0\n",
    "for i in range(len(valid_label)):\n",
    "    batch_data = valid_dataset[offset+i:offset+i+1]\n",
    "    batch_labels = valid_label[offset+i:offset+i+1].reshape((batch_size, 1))\n",
    "    predictions = sess.run(output, feed_dict={train_data_node: batch_data})[0][0]\n",
    "    predictions = float(int(round(predictions)))\n",
    "    if predictions == batch_data_all[i]:\n",
    "        correct+=1\n",
    "    results.append(predictions)\n",
    "print(batch_data_all[100:120])\n",
    "print(results[100:120])\n",
    "print(\"accuracy: \"+str(correct/len(valid_label)))\n",
    "confusions = np.zeros([10, 10], np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
