{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exp 1: a simple classifier with the barcode dataset\n",
    "The output layer is a classifier layer (one hot encoding)\n",
    "The training data is all 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sugartensor as tf\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64   # batch size\n",
    "image_size = 64\n",
    "pixel_depth = 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "Tensor(\"train_1:1\", shape=(64,), dtype=int64)\n",
      "Tensor(\"train_1:0\", shape=(64, 64, 64, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dir= \"barcode/train/\"\n",
    "fn = os.listdir(dir)\n",
    "total = len(fn)\n",
    "total\n",
    "# put all the images into this blob of size total*size*size*1\n",
    "# REMEMBER to change shape of dataset\n",
    "training_dataset = np.ndarray(shape = (total, image_size, image_size, 1), dtype = np.float32)\n",
    "counter = 0\n",
    "# REMEMBER to change shape of training label\n",
    "training_label = np.ndarray(shape = (total), dtype = np.int64)\n",
    "for file in fn:\n",
    "    image_data = (ndimage.imread(dir+file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "    if True:\n",
    "        training_label[counter] = int(file[0])\n",
    "        training_dataset[counter, :, :] = image_data[:,:,0].reshape(image_size, image_size, 1)\n",
    "        counter+=1\n",
    "print(len(training_label))\n",
    "training_image, training_label = tf.sg_data._data_to_tensor([training_dataset, training_label], batch_size, name = \"train\")\n",
    "print(training_label)\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "[8 1 7 1]\n",
      "Tensor(\"train_3:1\", shape=(64,), dtype=int64)\n",
      "Tensor(\"train_3:0\", shape=(64, 64, 64, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB4CAYAAADi1gmcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCQtdkjphoUtSJyx0SeqEhS5JnfgxCy+R4k+a+9wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f467bfdfa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir= \"barcode/valid/\"\n",
    "fn = os.listdir(dir)\n",
    "total = len(fn)\n",
    "total\n",
    "valid_label = np.ndarray(shape = (total), dtype = np.int64)\n",
    "valid_dataset = np.ndarray(shape = (total, image_size, image_size, 1), dtype = np.float32)\n",
    "counter = 0\n",
    "for file in fn:\n",
    "    image_data = (ndimage.imread(dir+file).astype(float) - \n",
    "                    pixel_depth / 2) / pixel_depth\n",
    "    if True:\n",
    "        valid_label[counter] = int(file[0])\n",
    "        valid_dataset[counter, :, :] = image_data[:,:,0].reshape(image_size, image_size, 1)\n",
    "        counter+=1\n",
    "print(len(valid_label))\n",
    "\n",
    "_, axs = plt.subplots(1, 4)\n",
    "\n",
    "label = valid_label[:4]\n",
    "image = valid_dataset[:4]\n",
    "print(label)\n",
    "for i in range(4):\n",
    "    axs[i].imshow(image[i].reshape(image_size, image_size), cmap=plt.cm.Greys);\n",
    "    axs[i].set_title(label[i])\n",
    "\n",
    "valid_image, valid_label = tf.sg_data._data_to_tensor([valid_dataset, valid_label], batch_size, name = \"train\")\n",
    "\n",
    "print(valid_label)\n",
    "print(valid_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# input images and label\n",
    "x = training_image\n",
    "y = training_label\n",
    "\n",
    "with tf.sg_context(name='discriminator', size=4, stride=2, act='leaky_relu'):\n",
    "        \n",
    "        # shared part\n",
    "        # have to set batch norm at the layer level because we dont want to use batch norm everywhere\n",
    "        logit = (x\n",
    "                  .sg_conv(dim=64, name = 'conv2', bn = True)\n",
    "                  .sg_conv(dim=128, name='conv3', bn = True)\n",
    "                  .sg_flatten()\n",
    "                  .sg_dense(dim=1024, name='fc1')\n",
    "                  .sg_dense(dim=10, act='linear', name = 'cat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"discriminator/cat/out:0\", shape=(64, 10), dtype=float32)\n",
      "Tensor(\"train_1:1\", shape=(64,), dtype=int64)\n",
      "INFO:tensorflow:Restoring parameters from asset/train/exp1-classifier/model.ckpt-0\n",
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   6%|█▋                        | 30/468 [00:09<01:16,  5.71b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.01197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  55%|█████████████▋           | 257/468 [00:19<00:08, 25.36b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.8036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   3%|▊                         | 14/468 [00:00<00:16, 26.77b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 22.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  56%|█████████████▉           | 262/468 [00:10<00:08, 24.79b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   9%|██▍                       | 43/468 [00:01<00:14, 29.42b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  63%|███████████████▋         | 294/468 [00:11<00:07, 23.29b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  85%|█████████████████████▎   | 400/468 [00:21<00:09,  7.19b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 10.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  37%|█████████▏               | 171/468 [00:06<00:10, 29.20b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  87%|█████████████████████▋   | 407/468 [00:16<00:02, 24.56b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 23.3999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   9%|██▎                       | 42/468 [00:01<00:16, 25.78b/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-82fcd9f36293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m        .sg_accuracy(target=valid_label, name='val'))\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# do training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msg_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'asset/train/exp1-classifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sugartensor/sg_train.py\u001b[0m in \u001b[0;36msg_train\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# run train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sugartensor/sg_train.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                         \u001b[0;31m# call train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                         \u001b[0;31m# loss history update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sugartensor/sg_train.py\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m(sess, arg)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msg_train_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# run train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(logit)\n",
    "print(y)\n",
    "loss = logit.sg_ce(target = y, name = 'disc_loss')\n",
    "# limit gpu\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "#\n",
    "# training\n",
    "#\n",
    "# accuracy evaluation\n",
    "acc = (logit.sg_reuse(input = valid_image).sg_softmax()\n",
    "       .sg_accuracy(target=valid_label, name='val'))\n",
    "# do training\n",
    "tf.sg_train(sess = sess, loss = loss, eval_metric=[acc], log_interval=10, max_ep=300, ep_size=30000//batch_size, early_stop=False, save_dir='asset/train/exp1-classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
